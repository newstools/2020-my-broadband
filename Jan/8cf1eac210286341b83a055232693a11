Facebook Inc. has shed more light on its efforts to eradicate doctored videos known as deepfakes, addressing an issue it’s identified as an emergent threat ahead of the U.S. election. The operator of the world’s largest social network pledged to remove content that has been “edited or synthesized” beyond adjustments for quality or clarity and is deemed likely to mislead viewers. Facebook emphasized, however, that its new rules will not apply to parody or satire. Facebook said videos that don’t immediately meet its internal criteria for removal may still get fact-checked by more than 50 organizations it’s partnered with worldwide. The company added that it will collaborate with Reuters to help newsrooms spot deepfakes through free online courses. Facebook has experienced the issues that come with manipulated media. Last year, a video of House Speaker Nancy Pelosi that had been edited to make it look like she was slurring her speech made the rounds on the social network. The video wasn’t technically a “deepfake,” which would mean it was completely fabricated, but still introduced Facebook to the kinds of misinformation it’ll face heading into the 2020 election. Facebook has since said it moved too slowly to curtail the reach of that video. “We are strengthening our policy toward misleading manipulated videos that have been identified as deepfakes,” Vice President of Global Policy Management Monika Bickert wrote in the blogpost. “While these videos are still rare on the internet, they present a significant challenge for our industry and society as their use increases.” Other U.S. internet giants are also tightening up on content ahead of the elections. Alphabet Inc.’s Google is restricting misinformation and banning deepfakes in ads following criticism that internet companies ran ads from U.S. President Donald Trump that were intentionally misleading. Facebook’s policy details were first reported by the Washington Post.